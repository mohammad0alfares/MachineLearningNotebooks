{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RegressionBasics_Part1.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammad0alfares/MachineLearningNotebooks/blob/master/RegressionBasics_Part1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5ofh8KNtLSW",
        "colab_type": "text"
      },
      "source": [
        "# Basics of Regression Techniques - Part1\n",
        "\n",
        "In this tutorial, we will explore the basics of regression techniques. We will be discussing Liner Regression, Multiple Regression, Cost Function and Gradient Descent. Click [here](https://github.com/mkjubran/MachineLearning/blob/master/1_Regression/LinearRegression.pdf) to download a brief presentation about some of the topics covered in this tutorial.\n",
        "\n",
        "**By the end of this tutorial**, you will be able to:\n",
        "-\tRecognize the topics to be covered in this tutorial.\n",
        "-\tMaster the concepts of linear and multivariant regression.\n",
        "-\tAcquire thorough knowledge of the mathematical formulation of cost function and cost function minimization in Machine Learning.\n",
        "-\tBe able to build and apply simple regression models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeQ0wuIc1AHR",
        "colab_type": "text"
      },
      "source": [
        "**Before Session**:\n",
        "-\tWatch a video about the main steps to build and apply machine learning algorithms (video source 1.1)\n",
        "-\tWatch two videos about linear regression to gain basic knowledge about linear regression, and to learn about modeling problems that can be solved using linear regression (video sources 1.2, 1.3, and 1.4)\n",
        "-\tRead about linear regression and gradient descent (reading sources 1.5 - 1.8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOLzzUpKwKpq",
        "colab_type": "text"
      },
      "source": [
        "**Resources:**\n",
        "\n",
        "1.1\tThe 7 Steps of Machine Learning (video): https://youtu.be/nKW8Ndu7Mjw\n",
        "\n",
        "1.2\tThe linear regression model (video): https://youtu.be/m88h75F3Rl8\n",
        "\n",
        "1.3\tSimple Linear Regression (video): https://www.youtube.com/watch?v=owI7zxCqNY0\n",
        "\n",
        "1.4\tRegression Analysis (video): https://youtu.be/DtOYBxi4AIE\n",
        "\n",
        "1.5\tLinear Regression Explained (reading): https://towardsdatascience.com/linear-regression-explained-d0a1068accb9 \n",
        "\n",
        "1.6\tLinear Regression â€” Detailed View (reading): https://towardsdatascience.com/linear-regression-detailed-view-ea73175f6e86\n",
        "\n",
        "1.7\tMachine learning fundamentals (I) (reading): Cost functions and gradient descent:   https://towardsdatascience.com/machine-learning-fundamentals-via-linear-regression-41a5d11f5220\n",
        "\n",
        "1.8\tCost Function, Gradient Descent and Univariate Linear Regression (reading): https://medium.com/@lachlanmiller_52885/machine-learning-week-1-cost-function-gradient-descent-and-univariate-linear-regression-8f5fe69815fd\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcB90Wu_twsA",
        "colab_type": "text"
      },
      "source": [
        "**Clone the Source GitHub Reporsitory**\n",
        "\n",
        "Before we start applying the procedure of this tutorial, we need to clone some source files to be used throughtout this tutorial from a GitHub reprository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmP4GrRNudXH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf ./MachineLearning\n",
        "!git clone https://github.com/mkjubran/MachineLearning.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIlzJbCpmo0R",
        "colab_type": "text"
      },
      "source": [
        "# Linear Regression\n",
        "**Introduction**\n",
        "\n",
        "In this section, we will come up with a technique to estimate the amount of spending of mall cutomers based on their annual income. This is achieved through the following procedure: \\\\\n",
        "1- collect some statistics about mall customers which include their annual income and spendings, \\\\\n",
        "2- we will use this data to build a model to correlate the spendings of the customers with their income, \\\\\n",
        "3- next, we will use the model to estimate the spendings of new customers based on their annual income."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RSwASngm9_9",
        "colab_type": "text"
      },
      "source": [
        "**Implementation**\n",
        "\n",
        "In a previous module, you learned how to extract and collect data. Now, let us assume the data which includes annual income and spendings of the mall customers which are saved in a csv file called \"Mall_Customers_short.csv\" \\\\\n",
        "To read the data in the file, we will be using the pandas library (https://pandas.pydata.org/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQX2iq_fnJOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"./MachineLearning/1_Regression/Mall_Customers_short.csv\")\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vENwLWQYucn",
        "colab_type": "text"
      },
      "source": [
        "You could also list values at the end of the dataframe using"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYIL8dxtY1np",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouhLIFflY4ak",
        "colab_type": "text"
      },
      "source": [
        "You could also print the whole data using"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w47VZB-BY8W2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJA9kY1o6_lr",
        "colab_type": "text"
      },
      "source": [
        "Now, to visualize the data, we will plot the pairs (Annual Income (K), Spendings) of each house on a scattered plot. To do this we need to use the matplotlib library (https://matplotlib.org/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ABqNIrJ7fLr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(df['Annual Income (K)'],df[['Spendings']],color='r', marker='+')\n",
        "plt.xlabel('Annual Income (K)',fontsize=20)\n",
        "plt.ylabel('Spendings',fontsize=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yZaiJXQ8NFv",
        "colab_type": "text"
      },
      "source": [
        "As can be observed from the plot, a straight line can be used to represent the data. So we will use the Linear Regression method in the sklearn library (https://scikit-learn.org/stable/) to derive the best fitting line (determine the best coefficient and interception values) based on the given data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lh4GU2-ROob8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import linear_model\n",
        "reg = linear_model.LinearRegression()\n",
        "reg.fit(df[['Annual Income (K)']],df[['Spendings']])\n",
        "print(reg.coef_) ## print the coefficient\n",
        "print(reg.intercept_) ## print the intercept"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axZLROWNOzaj",
        "colab_type": "text"
      },
      "source": [
        "To visualize the line, we plot the best fitting line on the scattered plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2UwirZYPHg5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.scatter(df[['Annual Income (K)']],df[['Spendings']],color='r', marker='+')\n",
        "plt.xlabel('Annual Income (K)',fontsize=20)\n",
        "plt.ylabel('Spendings',fontsize=20)\n",
        "plt.plot(df[['Annual Income (K)']],reg.predict(df[['Annual Income (K)']]),color='b')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CbQPKN8QKF6",
        "colab_type": "text"
      },
      "source": [
        "After building the model, we will use it to estimate the spendings of a list of new mall customers based on their annual income. Let us assume that the income of a list of new customers is stored in a csv file called \"Mall_Customers_short_new.csv\". We will read the data from the file into a dataframe, and apply the annual income values in the dataframe to the model to determine the estimated spendings, then we will append the estimated spenings to the dataframe and store the new dataframe to a new csv file called \"Predicted_Mall_Customers_short_new.csv\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0T7_4oYmmDo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2 = pd.read_csv(\"./MachineLearning/1_Regression/Mall_Customers_short_new.csv\")\n",
        "p=reg.predict(df2)\n",
        "df2['Spendings']=p\n",
        "print(df2)\n",
        "df2.to_csv('./MachineLearning/1_Regression/Predicted_Mall_Customers_short_new.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6hurFfaRXCm",
        "colab_type": "text"
      },
      "source": [
        "We could also plot the estimated spendings of cusromers in the original data and the best fitting line on the same figure as"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tP9gj5LqYilr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_merged= df.append(df2, ignore_index=True)\n",
        "\n",
        "plt.scatter(df[['Annual Income (K)']],df[['Spendings']],color='r', marker='+')\n",
        "plt.xlabel('Annual Income (K)',fontsize=20)\n",
        "plt.ylabel('Spendings',fontsize=20)\n",
        "plt.plot(df_merged[['Annual Income (K)']], reg.predict(df_merged[['Annual Income (K)']]),color='b',linestyle='-.',linewidth=0.5)\n",
        "plt.scatter(df2[['Annual Income (K)']],df2[['Spendings']],color='m', marker='o')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FR-SYXGGlBwr",
        "colab_type": "text"
      },
      "source": [
        "As can be observed from the figure, the estimated spendings of the new customers are located on the best fit line"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rFQOBBCtqlE",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 1.1:**\n",
        "\n",
        "Use linear regression to estimate the spendings of custoemrs based on their age. To complete this exercise, two files are included in the repository: \\\\\n",
        "1- Mall_Customer_Age_Spendings.csv: a list of customers ages and spendings \\\\\n",
        "2- Mall_Customer_Age.csv: a list of ages of new customers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f-VPoRayLM7",
        "colab_type": "text"
      },
      "source": [
        "# Multiple Regression\n",
        "**Introduction**\n",
        "\n",
        "In this section, we will extend the model derived in the Linear Regression section to include more than one independent variable. This method is called Multiple Regression. We will use the annual income of a family (Annual Income), the number of workers in the family (Working), and the number of children who are not working in the family (Kids) to estimate the level of spendings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsWik1emdqRJ",
        "colab_type": "text"
      },
      "source": [
        "**Implementation**\n",
        "\n",
        "Read the data in the file \"FamilySpendings.csv\" using pandas libarary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jL4EcjFsdp0m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"./MachineLearning/1_Regression/FamilySpendings.csv\")\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAsnCGlEhh0_",
        "colab_type": "text"
      },
      "source": [
        "In the above table, there is more than one feature that corresponds to the spendings of each family. In the multivariate, the number of input independent variables (features) is at least two or more. In our case, the features are Annual Income, Working (number of working family members), and Kids (number of kids in the family). And the dependent variable is the spendings of the family. \n",
        "\n",
        "We notice that the Working feature index 2 has a value of NaN, this is typically due to empty value in the csv file. Thus, we need to process the dataframe to clean the data. In our case, we will replace the NaN value with the rounded median of the other Working values in the table."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p415q6o7ma7y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "median_Working = df.Working.median() # media of number of working family members in dataframe\n",
        "print(median_Working)\n",
        "median_Working = math.floor(df.Working.median())# use the math library to compute the floor of the media of number of working family members in dataframe\n",
        "print(median_Working)\n",
        "df.Working = df.Working.fillna(median_Working) #replace the NAN with the median value\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1Fmyz__mPvw",
        "colab_type": "text"
      },
      "source": [
        "Now the data is clean. Next, we will use the LinearRegression method in the sklearn library (https://scikit-learn.org/stable/) to derive the best fitting line (determine the best coefficients and interception values) based on the given data. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEIeK_ZChge4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import linear_model\n",
        "regm = linear_model.LinearRegression()\n",
        "regm.fit(df[['Annual Income','Working','Kids']],df.Spendings)\n",
        "print(regm.coef_) ## print the coefficients\n",
        "print(regm.intercept_) ## print the intercept"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siDScZ1Q4nFs",
        "colab_type": "text"
      },
      "source": [
        "After building the model, we will use it to estimate the spendings of a list of new families based on their features (Annual Income,Working, Kids). Let us assume features of few families are stored in a csv file called \"FamilyIncomeWorkingKids.csv\". We will read the data from the file into a dataframe, and apply the values of the features in the dataframe to the model to determine the estimated spendings, then we will append the etimted spendings to the dataframe and store the new dataframe to new csv file called \"PredictedFamilySpendings.csv\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DA5CQ5Qy6TVp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfm = pd.read_csv(\"./MachineLearning/1_Regression/FamilyIncomeWorkingKids.csv\")\n",
        "p=regm.predict(dfm)\n",
        "dfm['Spendings']=p\n",
        "dfm.to_csv('./MachineLearning/1_Regression/PredictFamilySpendings.csv',index=False)\n",
        "dfm.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_uYKRTART1F",
        "colab_type": "text"
      },
      "source": [
        "Optional: we could also check the residul error between the actual spendings (in 'FamilySpendings.csv') and the predicted values. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ry8163yR5PS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ppr=regm.predict(df[['Annual Income','Working','Kids']])\n",
        "df['Predicted Spendings']=ppr\n",
        "df['Residual']=df['Spendings']-df['Predicted Spendings']\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAX3BodQ7OcN",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 1.2:** \\\\\n",
        "Use multiple regression to estimate the spending of a family based on the family (household) income, number of workers in the family, number of kids in the family, and city tax. You are given some data in the \"FamilySpendings_exercise.csv\" file included in the repository. You need to estimate the spendings of the following families:\n",
        "\n",
        "*Family One*: Two workers, two kids, an annual income of \\$30000, and pay \\$3000 taxes for the city.\n",
        "\n",
        "*Family Two*: One worker, one kid, an annual income of \\$20000, and pay \\$500 taxes for the city.\n",
        "\n",
        "*Family Three*: Two workers, two kids, an annual income of \\$30000, and you don't know how much taxes the family pays for the city."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hekbanaGUK6M",
        "colab_type": "text"
      },
      "source": [
        "# Cost Function and Gradient Descent\n",
        "In this section, we will learn how to use gradient descent to determine the optimal coefficients and intercept of linear regression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2fMSaUmUbDP",
        "colab_type": "text"
      },
      "source": [
        "**Implementation**\n",
        "\n",
        "In order to determine the best fit line, we need to determine the values of **m** and **b** of the straight line $\\hat{y}_i=mx_i+b$ that minimze the MSE. \n",
        "\n",
        "\\begin{equation}\n",
        "\\begin{aligned}\n",
        "MSE=J=\\frac{1}{n} \\sum^n_{i=1}{(y_i -\\hat{y}_i)^2}   \n",
        "\\end{aligned}\n",
        "\\end{equation}\n",
        "\n",
        "So we substitute $\\hat{y}_i=mx_i+b$ into the cost function as\n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "\\begin{aligned}\n",
        "J=\\frac{1}{n} \\sum^n_{i=1}{(y_i -mx_i+b)^2}   \n",
        "\\end{aligned}\n",
        "\\end{equation}\n",
        "\n",
        "Then, we determine the gradient by taking the partial derivative of the cost function with respect to **m** and **b** as\n",
        "\n",
        "\\begin{equation}\n",
        "\\begin{aligned}\n",
        "\\frac{\\partial J}{\\partial m}=\\frac{2}{n} \\sum^n_{i=1}{(y_i -mx_i+b) \\times (-x_i)} \n",
        "\\end{aligned}\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "\\begin{aligned}\n",
        "\\frac{\\partial J}{\\partial b}=\\frac{2}{n} \\sum^n_{i=1}{(y_i -mx_i+b) \\times (-1)} \n",
        "\\end{aligned}\n",
        "\\end{equation}\n",
        "\n",
        "So now to implement the gradient descent, we start with some values of **m** ($m_0$) and **b** ($b_0$) and iteratively modify them according the gradient and learning rate ($\\lambda$) as follows:\n",
        "\n",
        "\\begin{equation}\n",
        "\\begin{aligned}\n",
        "m_i = m_{i-1} - \\lambda \\times \\frac{\\partial J}{\\partial m} \n",
        "\\end{aligned}\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "\\begin{aligned}\n",
        "b_i = b_{i-1} - \\lambda \\times \\frac{\\partial J}{\\partial b} \n",
        "\\end{aligned}\n",
        "\\end{equation}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtAmR3az0onY",
        "colab_type": "text"
      },
      "source": [
        "Watch this annimation to visualize how gradient descent works https://github.com/mattnedrich/GradientDescentExample/blob/master/gradient_descent_example.gif"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MK89QcjYqdO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "def gradient_descent_basic(x,y,m_curr,b_curr,learning_rate,iterations):\n",
        "    n = len(x)\n",
        "    for i in range(iterations):\n",
        "        y_pred = m_curr * x + b_curr\n",
        "        \n",
        "        md = - ( 2 / n ) * sum( x * ( y - y_pred ))\n",
        "        bd = - ( 2 / n ) * sum(( y - y_pred ))\n",
        "\n",
        "        m_curr = m_curr - learning_rate * md \n",
        "        b_curr = b_curr - learning_rate * bd \n",
        "\n",
        "        J = ( 1 / n ) * sum(( y - y_pred )**2)\n",
        "\n",
        "        print('J = {}, m = {}, b = {}, Iteration = {}'.format(J ,m_curr, b_curr, i ))\n",
        "    return m_curr,b_curr,i,J\n",
        "\n",
        "## try the gradient_descent using sample data\n",
        "x = np.array([0,1,2,3]);\n",
        "y = np.array([1,3,5,7]); ## y=2x+1\n",
        "\n",
        "m_curr = 0; b_curr = 0;\n",
        "gradient_descent_basic(x,y,m_curr,b_curr,0.2,20) ## learning rate = 0.2 and iteration = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcFNmc4zeRtR",
        "colab_type": "text"
      },
      "source": [
        "Let us increase learning rate to 0.5 and see how the gradient descent converges."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pms6CmU-ei8G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## try the gradient_descent with learning rate = 0.5 and iteration = 20\n",
        "m_curr = 0; b_curr = 0;\n",
        "gradient_descent_basic(x,y,m_curr,b_curr,0.5,20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gOaimdMetgm",
        "colab_type": "text"
      },
      "source": [
        "As can be seen, the cost function increases instead of descreasing.\n",
        "\n",
        "So usually, we start with low iteration value and some value of learning rate and see if the cost function is reducing.  Then we increase the learning rate slowly to the value just before the cost function starts increasing. This value is the best learning rate (converge with the least number of iterations).\n",
        "\n",
        "Regarding the required number of iterations, you may stop the gradient descent search once the difference in the cost function between successive iterations reduces to less than some value (such as 1e-5 or 1e-6). Next we will modify the code to stop when the error (MSE) is less than 1e-6."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jo6-diDXwB9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import copy\n",
        "def gradient_descent(x,y,m_curr,b_curr,learning_rate,epochs):\n",
        "    n = len(x)\n",
        "    i = 0 \n",
        "    j_curr = 100000\n",
        "    while True:\n",
        "        i= i + 1\n",
        "        j_before = j_curr\n",
        "        y_pred = m_curr * x + b_curr\n",
        "        \n",
        "        md = - ( 2 / n ) * sum( x * ( y - y_pred ))\n",
        "        bd = - ( 2 / n ) * sum( y - y_pred )\n",
        "\n",
        "        m_curr = m_curr - learning_rate * md \n",
        "        b_curr = b_curr - learning_rate * bd \n",
        "\n",
        "        j_curr = ( 1 / n ) * sum(( y - y_pred )**2)\n",
        "\n",
        "        if ((abs(j_curr - j_before) < 1e-5) or (i >= epochs)):\n",
        "          return m_curr,b_curr,i,j_curr\n",
        "\n",
        "## try the gradient_descent using sample data\n",
        "x = np.array([0,1,2,3]);\n",
        "y = np.array([1,3,5,7]); ## y=2x+1\n",
        "\n",
        "m_curr = 0; b_curr = 0;\n",
        "gradient_descent(x,y,m_curr,b_curr,0.2,100) ## learning rate = 0.2 and iteration = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQJ2qOQhpA97",
        "colab_type": "text"
      },
      "source": [
        "Next, we will determine the cooeficient and intercept of the best fitting straigh line using linear regression (similar to the first part) and also by using our implementation of logistic regression. We will start by reading the data in the training dataset (.csv file)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3NI9Y7RmhzV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"./MachineLearning/1_Regression/Mall_Customers_Logitic_short.csv\")\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwM6GRhO8pyw",
        "colab_type": "text"
      },
      "source": [
        "To plot this data using scatter plot, use:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aei3Ue548qLY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(df['Annual Income'],df[['Spendings']],color='r', marker='+')\n",
        "plt.xlabel('Annual Income (K)',fontsize=20)\n",
        "plt.ylabel('Spendings',fontsize=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V81zx7Gs4xH3",
        "colab_type": "text"
      },
      "source": [
        "Let us begin by determine the linear regression coefficients as done in the Liner regression section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwIkdrBb433D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import linear_model\n",
        "reg = linear_model.LinearRegression()\n",
        "reg.fit(df[['Annual Income']],df[['Spendings']])\n",
        "print(reg.coef_) ## print the coefficient\n",
        "print(reg.intercept_) ## print the intercept\n",
        "\n",
        "m_reg = reg.coef_\n",
        "b_reg = reg.intercept_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mP0Datcn86zr",
        "colab_type": "text"
      },
      "source": [
        "To plot this line:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kg7PDNI9FN9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.scatter(df[['Annual Income']],df[['Spendings']],color='r', marker='+')\n",
        "plt.xlabel('Annual Income (K)',fontsize=20)\n",
        "plt.ylabel('Spendings',fontsize=20)\n",
        "plt.plot(df[['Annual Income']],reg.predict(df[['Annual Income']]),color='b')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tdO_CtTnHhm",
        "colab_type": "text"
      },
      "source": [
        "Let us begin by determining the learning rate. We will use gradient_descent_basic() to print error while trying different learning rate values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAB1F_bn2TGq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=np.array(df[['Annual Income']])\n",
        "y=np.array(df[['Spendings']])\n",
        "## change the learning rate and iterations\n",
        "m_gd, b_gd, iters, j_curr= gradient_descent_basic(x,y,0,0,0.0000000001,20)\n",
        "print('J= {}, m = {}, b = {}, iterations = {}'.format(j_curr, m_gd, b_gd,iters))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqN0-ca6n0cq",
        "colab_type": "text"
      },
      "source": [
        "As can be observed, we need to use very low learning rate to make sure error is decreasing. However, such a low learning rate needs a lot of iterations to converge. To deal with this we apply data scaling. So we scale the independent random variable according to its mean and standard deviations. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtQvQovRoZo1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=np.array(df[['Annual Income']])\n",
        "y=np.array(df[['Spendings']])\n",
        "\n",
        "## scaling the independent random variable\n",
        "x_new = (x - np.mean(x)) / np.std(x)\n",
        "\n",
        "## change the learning rate and iterations\n",
        "m_gd, b_gd, iters, j_curr= gradient_descent_basic(x_new,y,0,0,0.01,20)\n",
        "print('J = {}, m = {}, b = {}, iterations = {}'.format(j_curr, m_gd, b_gd,iters))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yp7Ih9WmqrF7",
        "colab_type": "text"
      },
      "source": [
        "Now, to find the best coefficients, we increase the number of iterations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YTt_fwzqzIQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## change the learning rate and iterations\n",
        "m_gd, b_gd, iters, j_curr= gradient_descent(x_new,y,0,0,0.01,20000)\n",
        "print('With data scaling: J = {}, m = {}, b = {}, iterations = {}'.format(j_curr, m_gd, b_gd,iters))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RirEHpNwuc3H",
        "colab_type": "text"
      },
      "source": [
        "Notice that the number of iterations required such that the difference between MSE of successive iterations is less than 1e-5 is 338 only."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-3pKQAYtzNd",
        "colab_type": "text"
      },
      "source": [
        "As an in class exercise, we will compare the error function between the rg.fit method (linear regression section) and the gradient descent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-bQ-1xg8dd0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m_reg ## from Linear Regression in code cell above\n",
        "b_reg ## from Linear Regression in code cell above\n",
        "\n",
        "m_gd ## from gradient descient results in code cell above\n",
        "b_gd ## from gradient descient results in code cell above\n",
        "\n",
        "y_actual = np.array(df.Spendings)\n",
        "\n",
        "y_pred_reg = m_reg * x + b_reg;\n",
        "\n",
        "y_pred_gd = m_gd * x_new + b_gd;\n",
        "\n",
        "n=len(y_actual)\n",
        "\n",
        "J_reg = (1/n)*sum(abs(y_actual - y_pred_reg[:,0]));\n",
        "J_gd = (1/n)*sum(abs(y_actual - y_pred_gd[:,0]));\n",
        "\n",
        "dif = J_reg - J_gd;\n",
        "\n",
        "print('J_reg = {}, \\n\\nJ_gd = {}, \\n\\nDifference = {}'.format(J_reg, J_gd, dif))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3JbTFOTDVZn",
        "colab_type": "text"
      },
      "source": [
        "As can be seen the coefficients are not the same. However the difference between MSE of both methods is very small. Let us try to plot the reg.fit line and gradient descent line on the same plot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3E1OOkaudEy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(df[['Annual Income']],df[['Spendings']],color='r', marker='+')\n",
        "plt.xlabel('Annual Income',fontsize=20)\n",
        "plt.ylabel('Spendings',fontsize=20)\n",
        "plt.plot(df[['Annual Income']],y_pred_reg,color='b',label='reg.fit') ## best fit line using reg.predict\n",
        "plt.plot(df[['Annual Income']],y_pred_gd,color='g',linestyle='--',linewidth=3,label='Gradient Descent') ## best fit line using gradient descent\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8rvtRECsIlv",
        "colab_type": "text"
      },
      "source": [
        "As can be seen, the reg.fit and the gradient descent lines are exactly the same.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lx8B1I8uwnZa",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 1.3 (optional):**\n",
        "\n",
        "Modify the gradient descent to be used for multiple linear regression with three independent variables. Then use it to estimate the spendings given the annual income, number of persons working in the family, and number of kids discussed in the multiple linear regression section."
      ]
    }
  ]
}