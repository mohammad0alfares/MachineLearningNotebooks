{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RegressionBasics_Part2.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammad0alfares/MachineLearningNotebooks/blob/master/RegressionBasics_Part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzmEcNHzuBI3",
        "colab_type": "text"
      },
      "source": [
        "# Basics of Regression Techniques - Part2\n",
        "\n",
        "In this tutorial, we will continue exploring the basics of regression techniques. We will be discussing Saving and Loading Training Models, One Hot Encoding, and Model Accuracy. \n",
        "\n",
        "**By the end of this tutorial**, you will be able to:\n",
        "-\tSave and load inference models.\n",
        "-\tApply multiple leaner regression to a categorical data.\n",
        "-\tMeasure the accuracy of inference model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HK6TLSfl86GE",
        "colab_type": "text"
      },
      "source": [
        "**Before Session**:\n",
        "-\tRead about how to save and load Machine Learning Models (reading source 2.1)\n",
        "-\tRead about how to encode labeled data for machine learning algorithms (reading sources 2.2 â€“ 2.5)\n",
        "-\tRead about how to evaluate the accuracy of inference models (reading source 2.6 and 2.7)\n",
        "-\tWatch a video about how to evaluate the accuracy of inference models ( video source 2.8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWM6M8ZI87Gj",
        "colab_type": "text"
      },
      "source": [
        "**Resources:**\n",
        "\n",
        "2.1\tSave and Load Machine Learning Models in Python with scikit-learn (reading): https://machinelearningmastery.com/save-load-machine-learning-models-python-scikit-learn/\n",
        "\n",
        "2.2\tWhat is One Hot Encoding and How to Do It (reading): https://medium.com/@michaeldelsole/what-is-one-hot-encoding-and-how-to-do-it-f0ae272f1179\n",
        "\n",
        "2.3\tCategorical encoding using Label-Encoding and One-Hot-Encoder (reding): https://towardsdatascience.com/categorical-encoding-using-label-encoding-and-one-hot-encoder-911ef77fb5bd\n",
        "\n",
        "2.4\tOne Hot Encoding (reading): https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f\n",
        "\n",
        "2.5\tOne Hot Encoding with Python | Handling Categorical Data (video): https://youtu.be/YOR6rQTTEAQ\n",
        "\n",
        "2.6\tDifference between Loss, Accuracy, Validation loss, Validation accuracy (reading): https://www.javacodemonk.com/difference-between-loss-accuracy-validation-loss-validation-accuracy-in-keras-ff358faa\\\n",
        "\n",
        "2.7\tTrain/Test Split (reading): https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6\n",
        "\n",
        "2.8\tThe 7 Steps of Machine Learning (video): https://youtu.be/nKW8Ndu7Mjw\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jl4zpwKY9Jk6",
        "colab_type": "text"
      },
      "source": [
        "**Clone the Source GitHub Reporsitory**\n",
        "\n",
        "Before we start applying the procedure of this tutorial, we need to clone some source files to be used throughtout this tutorial from a GitHub reprository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmP4GrRNudXH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf ./MachineLearning\n",
        "!git clone https://github.com/mkjubran/MachineLearning.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQWDGoDt9Shn",
        "colab_type": "text"
      },
      "source": [
        "# Saving and Loading Training Models\n",
        "\n",
        "In this section we will learn how to save and load training models. We will do that using two methods; Pickle and Joblib."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDBxeJFH9n0L",
        "colab_type": "text"
      },
      "source": [
        "First, we will create and train the linear regression model usied in the linear regresison section. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sy4ivzgM9qDz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn import linear_model\n",
        "\n",
        "df = pd.read_csv(\"./MachineLearning/1_Regression/Mall_Customers_Logitic_short.csv\")\n",
        "\n",
        "reg = linear_model.LinearRegression()\n",
        "reg.fit(df[['Annual Income']],df[['Spendings']])\n",
        "\n",
        "print(reg.coef_) ## print the coefficient\n",
        "print(reg.intercept_) ## print the intercept\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7CiDfyZ9sxO",
        "colab_type": "text"
      },
      "source": [
        "Now, we will save the **reg** linear model using **pickle** library (https://docs.python.org/3/library/pickle.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXUa5Z5H9vyP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "with open('./SpendingsLinearModel.pickle','wb') as f:\n",
        "  pickle.dump(reg,f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfmCjD5v9yCz",
        "colab_type": "text"
      },
      "source": [
        "The **SpendingsLinearModel** is saved at your current directory (.\\content\\) and includes the linear regression model. It doesn't include the dataframes or any other libraries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kp0begCy90gO",
        "colab_type": "text"
      },
      "source": [
        "To load the model, we will use another method from the pickle library as:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o95GSpWz92ja",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('./SpendingsLinearModel.pickle','rb') as f:\n",
        "  reg_pickle = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjQIOJto95ep",
        "colab_type": "text"
      },
      "source": [
        "We could now use the new model to predict the prices of houses based on their areas as done before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fs-2e-b0971Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2 = pd.read_csv(\"./MachineLearning/1_Regression/Mall_Customers_short_new.csv\")\n",
        "print(df2)\n",
        "p=reg_pickle.predict(df2)\n",
        "df2['Spendings_new']=p\n",
        "df2.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xzt5IkU9-bc",
        "colab_type": "text"
      },
      "source": [
        "Another approach to save the reg linear model is by using joblib from sklearn library (https://scikit-learn.org/stable/modules/model_persistence.html) as:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqFt6w_79_CJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import joblib as jb\n",
        "jb.dump(reg, './SpendingsLinearModel.joblib') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiH2PIcT-BDd",
        "colab_type": "text"
      },
      "source": [
        "In this case there is no need to open file before dumping the data. similarly for loading data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOPsFPj5-Eyp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reg_joblib = jb.load('./SpendingsLinearModel.joblib')\n",
        "\n",
        "df2 = pd.read_csv(\"./MachineLearning/1_Regression/Mall_Customers_short_new.csv\")\n",
        "print(df2)\n",
        "p=reg_joblib.predict(df2)\n",
        "df2['Spendings']=p\n",
        "df2.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ef5Vv2J9TIN",
        "colab_type": "text"
      },
      "source": [
        "If you need to learn more about pickle and joblib refer to https://scikit-learn.org/stable/modules/model_persistence.html ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIlzJbCpmo0R",
        "colab_type": "text"
      },
      "source": [
        "# One Hot Encoding\n",
        "**Introduction**\n",
        "\n",
        "In this section, we will apply multiple linear regression to a categorical data. \n",
        "\n",
        "We will be using the **One hot encoding** to convert nominal categorical variables into a form that could be provided to ML algorithms for linear regression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RSwASngm9_9",
        "colab_type": "text"
      },
      "source": [
        "**Implementation**\n",
        "\n",
        "Read the input data from a csv file called \"FamilyCitySpendings.csv\" \\\\\n",
        "To read the data in the file, we will be using the pandas library (https://pandas.pydata.org/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQX2iq_fnJOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"./MachineLearning/1_Regression/FamilyCitySpendings.csv\")\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVIVhFFVLVjA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.groupby(['City'])['City'].count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdTb79jLh1mU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Kids'].max()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IosK38xni1eJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.loc[df['Kids'].idxmax()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJA9kY1o6_lr",
        "colab_type": "text"
      },
      "source": [
        "As can be seen, one of the fields (city) contains nominal categorical variable. Thus we need to encode this field into numeric values using one-hot coding. We wil use the pd.get_dummies(df.City) method as"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryh3BJOV7eo1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dm = pd.get_dummies(df.City)\n",
        "dm.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39M2I3LU70dB",
        "colab_type": "text"
      },
      "source": [
        "After executing the above command we get a table with a code per city. Now we need to concatenate these rows to the original (df) dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtqBhjVN8Hgl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_merge = pd.concat([df,dm],axis='columns')\n",
        "df_merge.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HHv5Gko8_20",
        "colab_type": "text"
      },
      "source": [
        "Now we need to get the multiple regression model. Note we pass the 'Annual Income', 'Working', 'Kids', and the code of two of the city dummy variables ('Jerusalem' and 'Ramallah') to train the model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBkR7WTW9T7j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import linear_model\n",
        "regm = linear_model.LinearRegression()\n",
        "regm.fit(df_merge[['Annual Income',\t'Working','Kids','Jerusalem','Ramallah']],df_merge[['Spendings']])\n",
        "print(regm.coef_) ## print the coefficients\n",
        "print(regm.intercept_) ## print the intercept"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yg0bQjS5CMlB",
        "colab_type": "text"
      },
      "source": [
        "Alternatively, we could clean the data frame by dropping the not needed fields from the data frame and then define the inout variables to the modelas "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCfpxkOSCuRq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x= df_merge.drop(['Nablus','City','Spendings'],axis=1)\n",
        "print(x.head())\n",
        "y = df_merge[['Spendings']]\n",
        "print(y.head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eXLcFhJE1DU",
        "colab_type": "text"
      },
      "source": [
        "To train the model using x and y:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaa_QikPEzwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "regm.fit(x,y)\n",
        "print(regm.coef_) ## print the coefficients\n",
        "print(regm.intercept_) ## print the intercept"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zd0a13CuAMmf",
        "colab_type": "text"
      },
      "source": [
        "The model is now ready. To estimate the spendings of a family from Ramallah with an annual income of $20000 and two persons working. The family has only one kid. We first create a new dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuvM1TH8Anv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_ = pd.DataFrame(index=None,columns=None)\n",
        "x_['Annual Income'] = [20000]\n",
        "x_['Working'] = [2]\n",
        "x_['Kids'] = [1]\n",
        "x_['Jerusalem'] = [0]\n",
        "x_['Ramallah'] = [1]\n",
        "x_.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQQySHFZ1BKN",
        "colab_type": "text"
      },
      "source": [
        "Then apply to the new dataframe to the regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNcRrxSS1KdJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "regm.predict(x_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XM1K3MRs1Ofr",
        "colab_type": "text"
      },
      "source": [
        "Alternatively, we could apply the family data directly to the regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwHHPp781ZIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "regm.predict([[20000,2,1,0,1]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCJamP0C1tbA",
        "colab_type": "text"
      },
      "source": [
        "**Is the order we apply the data to the regressor important?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV6Pc0FJL7AG",
        "colab_type": "text"
      },
      "source": [
        "The spendings of a family with \\$20000 annual income, 2 persons working, and 1 kid is about \\$187543. Let us next compare this with same family living in other cities. Use the city code based on the one hot coding shwon in output cell [37]. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fv4n1EhxMVK7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Ramallah = [0 1]\n",
        "## Jerusalem = [1 0]\n",
        "## Nablus = [ 0 ]\n",
        "\n",
        "x_=[[20000,2,1,0,1],[20000,2,1,1,0],[20000,2,1,0,0]]\n",
        "regm.predict(x_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggh_Kpl9j9dr",
        "colab_type": "text"
      },
      "source": [
        "What about the accuracy of the model. We can view the accuracy of the model by printing the score as"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxujdNZDkIvZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "regm.score(x,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWJlXJcokudK",
        "colab_type": "text"
      },
      "source": [
        "The accuracy of the model is about $98.899\\%$. This is called the training accuracy because the data used for training is used to compute the model accuracy. Having high training accuracy means the model fitted the training data very well and the relationship of the training data is linear. However, we need to measure the accuracy of the model to predict the prices of new data not used for training. This will be discussed in the next section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rFQOBBCtqlE",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 2.1:**\n",
        "\n",
        "Use multiple linear regression to estimate the prices of the following cars:\n",
        "\n",
        "Specifications | Car #1 | Car #2 | Car #3\n",
        "-- | --- | --- | ---\n",
        "Make    |  BMW | Audi | Nissan\n",
        "Model    | 1 Series M | 100 | 370z\n",
        "Year      |      2011 | 1992 | 2106\n",
        "Engine Fuel Type|  premium unleaded (required) | regular unleaded | premium unleaded (required)\n",
        "Engine HP        |   335 |172 | 332\n",
        "Engine Cylinders  |   6 | 6 | 6\n",
        "Transmission Type  |   MANUAL | MANUAL | MANUAL\n",
        "Driven_Wheels      |  rear wheel drive | all wheel drive | rear wheel drive\n",
        "Number of Doors    |    2 | 4 | 2\n",
        "Market Category    |  Factory Tuner,Luxury,High-Performance | Luxury | High-Performance\n",
        "Vehicle Size       |   Compact | Midsize | Compact\n",
        "Vehicle Style      |    Coupe | Sedan | Coupe\n",
        "highway MPG        |     26 | 21 | 26\n",
        "city mpg           |     19 | 16 | 18\n",
        "Popularity         |   3916 | 3105 | 2009\n",
        "\n",
        "You may use a subset of the car features to train and predict prices. We will use the data set in the 'CarPrices.csv' file in the Github repository to train the model. This data set is downloaded from kaggle. $^{[1]}$ \n",
        "\n",
        "\n",
        "[1] https://www.kaggle.com/CooperUnion/cardataset/data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtH_ZryIZOGc",
        "colab_type": "text"
      },
      "source": [
        "To read and view specific row of the data set, use the following code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJ3KaBA0UvWV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df_cars = pd.read_csv(\"./MachineLearning/1_Regression/carsdataset.csv\")\n",
        "row=100\n",
        "print(df_cars.loc[row,:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zQ-GrYLnc9g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## check null values \n",
        "pd.isnull(df_cars).sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aR1faM2Ss-S9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('dim before drop null ',df_cars.shape)\n",
        "df_cars= df_cars.dropna()\n",
        "print('dim after drop null ',df_cars.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnngrjAlr3Sk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "col = 'Make'\n",
        "df_cars.groupby([col])[col].count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0p557tBo4PE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_cars.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10GhWfiHqIJc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_cars.select_dtypes(include='object').columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjt863gCuGyd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dm_cars = pd.get_dummies(data =df_cars[df_cars.select_dtypes(include='object').columns], columns= df_cars.select_dtypes(include='object').columns )\n",
        "dm_cars.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kn9k0EV8wwbR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dm_cars"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JR6zoCyxkAr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_cars_ex = df_cars.select_dtypes(exclude=['object'])\n",
        "df_merge_cars = pd.concat([df_cars_ex,dm_cars],axis='columns')\n",
        "df_merge_cars.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTh22tbA_Xkn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_merge_cars.columns\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDD0R9s3CkSv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_merge_cars.select_dtypes(include='object').columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjjfXmXcDdSb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x= df_merge_cars.drop(['MSRP'], axis=1)\n",
        "y= df_merge_cars[['MSRP']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSwECtI3Ecif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_j9-BttDDNO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import linear_model\n",
        "regm = linear_model.LinearRegression()\n",
        "regm.fit(x,y)\n",
        "print(regm.coef_) ## print the coefficients\n",
        "print(regm.intercept_) ## print the intercept"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gB7FKJ9fE1cg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "regm.score(x,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-kiZH_qFLfF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = [['BMW','1 Series M',2011,'premium unleaded (required)',335,6,'MANUAL','rear wheel drive',2,'Factory Tuner,Luxury,High-Performance','Compact','Coupe',26,19,3916],\n",
        "        ['Audi','100',1992,'regular unleaded',172,6,'MANUAL','all wheel drive',4,'Luxury','Midsize','Sedan',21,16,3105],\n",
        "\t\t\t\t    ['Nissan','370z',2106,'premium unleaded (required)',332,6,'MANUAL','rear wheel drive',2,'High-Performance','Compact','Coupe',26,18,2009]]\n",
        "\n",
        "df_data = pd.DataFrame(data, columns = ['Make','Model','Year','Engine Fuel Type','Engine HP','Engine Cylinders','Transmission Type','Driven_Wheels','Number of Doors','Market Category','Vehicle Size','Vehicle Style','highway MPG','city mpg','Popularity']) \n",
        "df_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xl_nCj_jmeUp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYmQ7u1mGZMQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rY_DT_ZrIiYC",
        "colab_type": "text"
      },
      "source": [
        "# Model Accuracy\n",
        "\n",
        "In this section, we will learn how to measure the accuracy of a model. This requires splitting the available dataset into a training dataset and testing dataset. The training dataset will be used to derive the coefficients of the model. whereas the testing dataset will be used to measure the model accuracy which is sometimes referred to as testing accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTjGIsgEMl1l",
        "colab_type": "text"
      },
      "source": [
        "In this section, we will use part of the cars dataset used in the exercise above. This dataset is stored in the 'carsdataset_short.csv' in the repository."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZJ5BZRTNFXi",
        "colab_type": "text"
      },
      "source": [
        "To load the dataset we will use the panda library as before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0SRCu49NMxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "cars = pd.read_csv(\"./MachineLearning/1_Regression/carsdataset_short.csv\")\n",
        "print(cars)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51swnXPKQVvL",
        "colab_type": "text"
      },
      "source": [
        "Now we will use one hot coding to represent the car make as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HVX9z_jQhEg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CarMake = pd.get_dummies(cars.Make)\n",
        "cars_merge = pd.concat([cars, CarMake], axis=1)\n",
        "x = cars_merge.drop(['Make','price','Mercedes-Benz'],axis=1)\n",
        "y = cars_merge.price\n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8h5eUBGBP1Xf",
        "colab_type": "text"
      },
      "source": [
        "Now, we need to split the datset into training and testing datsets. We will use 80% of the dataset for training and the rest will be used for testing. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCmJEuybQFYZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2)\n",
        "print(len(x))\n",
        "print(len(x_train))\n",
        "print(len(x_test))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkZNw0hfTOnV",
        "colab_type": "text"
      },
      "source": [
        "next we will train the linear regresison model using the training dataset as"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmM1vi8NTV38",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import linear_model\n",
        "regm = linear_model.LinearRegression()\n",
        "regm.fit(x_train,y_train)\n",
        "print(regm.coef_) ## print the coefficients\n",
        "print(regm.intercept_) ## print the intercept"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIE3594bT8LI",
        "colab_type": "text"
      },
      "source": [
        "We will use the model now to predict the prices of the test datset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEBluiFpUJzn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "price_test = regm.predict(x_test)\n",
        "print(price_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdc7rVxNjyRl",
        "colab_type": "text"
      },
      "source": [
        "To combine the actual prices of the test data sets and the predicted prices for observation use the following "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlzTMWN-jzGZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test_pred = pd.DataFrame.copy(y_test)\n",
        "y_test_pred = y_test_pred.to_frame()\n",
        "y_test_pred['pprice'] = price_test\n",
        "y_test_pred['difference'] = y_test_pred['price'] - y_test_pred['pprice']\n",
        "print(y_test_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yeL9tHUUZyx",
        "colab_type": "text"
      },
      "source": [
        "The model accuracy can be obtained as follows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJcak-QoUmbF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#training accuracy\n",
        "Acc_train = regm.score(x_train,y_train)\n",
        "print(Acc_train)\n",
        "#testing accuracy\n",
        "Acc_test = regm.score(x_test,y_test)\n",
        "print(Acc_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCcKv8lxVCbB",
        "colab_type": "text"
      },
      "source": [
        "As expected, the training accuracy is greater than the testing accuracy. A high training accuracy means that the model fits very well hr training data and a high testing accuracy means that the model can be generalized to other samples or datasets."
      ]
    }
  ]
}